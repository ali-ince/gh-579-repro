# This file is automatically @generated by Poetry 1.7.1 and should not be changed by hand.

[[package]]
name = "py4j"
version = "0.10.9.7"
description = "Enables Python programs to dynamically access arbitrary Java objects"
optional = false
python-versions = "*"
files = [
    {file = "py4j-0.10.9.7-py2.py3-none-any.whl", hash = "sha256:85defdfd2b2376eb3abf5ca6474b51ab7e0de341c75a02f46dc9b5976f5a5c1b"},
    {file = "py4j-0.10.9.7.tar.gz", hash = "sha256:0b6e5315bb3ada5cf62ac651d107bb2ebc02def3dee9d9548e3baac644ea8dbb"},
]

[[package]]
name = "pyspark"
version = "3.5.0"
description = "Apache Spark Python API"
optional = false
python-versions = ">=3.8"
files = [
    {file = "pyspark-3.5.0.tar.gz", hash = "sha256:d41a9b76bd2aca370a6100d075c029e22ba44c5940927877e9435a3a9c566558"},
]

[package.dependencies]
py4j = "0.10.9.7"

[package.extras]
connect = ["googleapis-common-protos (>=1.56.4)", "grpcio (>=1.56.0)", "grpcio-status (>=1.56.0)", "numpy (>=1.15)", "pandas (>=1.0.5)", "pyarrow (>=4.0.0)"]
ml = ["numpy (>=1.15)"]
mllib = ["numpy (>=1.15)"]
pandas-on-spark = ["numpy (>=1.15)", "pandas (>=1.0.5)", "pyarrow (>=4.0.0)"]
sql = ["numpy (>=1.15)", "pandas (>=1.0.5)", "pyarrow (>=4.0.0)"]

[metadata]
lock-version = "2.0"
python-versions = "^3.12"
content-hash = "cb471c92647a03b9e1c21b34db71d7b79d77b962ea8f6f896f403abe74fe7ae0"
